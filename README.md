# FoxAndGoose

## Special Considerations

- 描述狐狸和鹅的 `action space`
    首先，action space 需要是有限的，需要考虑如何描述两个角色的动作空间才能保证动作空间有限、完整、无重复。
    对于狐狸，其行动包含了一共八个方向，即上下左右四个方向，以及四个斜方向。在不吃掉鹅的行动步骤中，可以表述为“狐狸朝 v 方向移动 n=1 步”；在吃掉鹅的行动步骤中，可以表述为“狐狸朝 v 方向移动 n≠1 步并吃掉鹅”。而在 7x7 的棋盘上，n的取值有且仅有：1, 2, 4, 6 共四种。此外还需考虑狐狸在吃掉鹅的后续行动中可能出现没有下一步的情况，即狐狸无法再次移动，需要额外加多一个静止的动作，仅在已经吃掉鹅的情况下才能生效。综上，狐狸的动作空间最大为 8 * 4 + 1 = 33。
    对于鹅，其行动包含了一共八个方向，且需要同时描述多个鹅的行动。考虑到每一轮次有且仅有一只鹅可以移动，因此可以描述为“第 k 只鹅向 v 方向移动一步”。同上，鹅的动作空间最大为 15 * 8。
- 保证鹅个体之间的**无序性**

    维护鹅的位置存储序列升序即可保证训练与推理时的一致。
- 描述棋盘行动规则

    将每个行动描述为，方向+步数，枚举棋盘 33 个位置的所有可能行动，枚举过程包含优化操作。
- 避免非法行动
    根据棋盘行动规则与狐狸、鹅的动作空间，在每一轮次中分别对狐狸与鹅的动作空间进行遮罩，保证待选的行动均为合法行动。
- PPO 算法的输入状态
    将棋盘状态转化为 33 位的编码，包含狐狸、鹅、空位三种状态，加速网络训练及推理。
- 如何设计奖励函数
    **TODO**
